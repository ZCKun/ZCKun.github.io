<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="前言   上午写完那篇文章后，下午在睡觉，晚上就想试试scrapy比较一下速度，那个更快，我是第一次用scrapy下载图片，第一次我使用requests下载的。。。贼鸡儿慢，就是单线程；后来翻了翻文档按照官方的例子改了改算是成功了，这篇文章就说一下我遇到的坑吧，文末对比两者速度">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Scrapy - Ins爬虫">
<meta property="og:url" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/index.html">
<meta property="og:site_name" content="0x2h">
<meta property="og:description" content="前言   上午写完那篇文章后，下午在睡觉，晚上就想试试scrapy比较一下速度，那个更快，我是第一次用scrapy下载图片，第一次我使用requests下载的。。。贼鸡儿慢，就是单线程；后来翻了翻文档按照官方的例子改了改算是成功了，这篇文章就说一下我遇到的坑吧，文末对比两者速度">
<meta property="og:locale">
<meta property="og:image" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/images/1.jpg">
<meta property="og:image" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/images/2.jpg">
<meta property="og:image" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/images/3.jpg">
<meta property="og:image" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/images/4.jpg">
<meta property="article:published_time" content="2019-05-16T16:53:46.000Z">
<meta property="article:modified_time" content="2019-07-24T06:49:16.000Z">
<meta property="article:author" content="0x2h">
<meta property="article:tag" content="python">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="scrapy">
<meta property="article:tag" content="crawl">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/images/1.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Python Scrapy - Ins爬虫</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2019/06/08/python-frida-hook-quick-start-19-06-08/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2019/05/16/python-coroutine-ins-crawl-19-05-16/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&text=Python Scrapy - Ins爬虫"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&is_video=false&description=Python Scrapy - Ins爬虫"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python Scrapy - Ins爬虫&body=Check out this article: http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&name=Python Scrapy - Ins爬虫&description=&lt;h2 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;  上午写完那篇文章后，下午在睡觉，晚上就想试试scrapy比较一下速度，那个更快，我是第一次用scrapy下载图片，第一次我使用requests下载的。。。贼鸡儿慢，就是单线程；后来翻了翻文档按照官方的例子改了改算是成功了，这篇文章就说一下我遇到的坑吧，文末对比两者速度&lt;/p&gt;
&lt;/blockquote&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%96%87"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C"><span class="toc-number">2.0.1.</span> <span class="toc-text">运行</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Python Scrapy - Ins爬虫
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">0x2h</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2019-05-16T16:53:46.000Z" itemprop="datePublished">2019-05-17</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/crawl/" rel="tag">crawl</a>, <a class="tag-link-link" href="/tags/python/" rel="tag">python</a>, <a class="tag-link-link" href="/tags/scrapy/" rel="tag">scrapy</a>, <a class="tag-link-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote>
<p>  上午写完那篇文章后，下午在睡觉，晚上就想试试scrapy比较一下速度，那个更快，我是第一次用scrapy下载图片，第一次我使用requests下载的。。。贼鸡儿慢，就是单线程；后来翻了翻文档按照官方的例子改了改算是成功了，这篇文章就说一下我遇到的坑吧，文末对比两者速度</p>
</blockquote>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>站点分析就免去了，看上一片文章</p>
<p>首先新建一个项目</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  scrapy git:(master) ✗ scrapy startproject ins_crawl</span><br></pre></td></tr></table></figure>

<p>接着生成spider：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  scrapy git:(master) ✗ cd ins_crawl</span><br><span class="line">➜  ins_crawl git:(master) ✗ scrapy genspider ins instagram.com</span><br></pre></td></tr></table></figure>

<p>为了方便观看，我先tree一下我项目：</p>
<blockquote>
<p>  .<br>  ├── ins_crawl<br>  │   ├── <strong>init</strong>.py<br>  │   ├── <strong>pycache</strong><br>  │   │   ├── <strong>init</strong>.cpython-37.pyc<br>  │   │   ├── items.cpython-37.pyc<br>  │   │   ├── middlewares.cpython-37.pyc<br>  │   │   ├── pipelines.cpython-37.pyc<br>  │   │   └── settings.cpython-37.pyc<br>  │   ├── images<br>  │   │   ├── InsImagesPipeline.py<br>  │   │   ├── <strong>init</strong>.py<br>  │   │   └── <strong>pycache</strong><br>  │   │       ├── InsImagesPipeline.cpython-37.pyc<br>  │   │       └── <strong>init</strong>.cpython-37.pyc<br>  │   ├── items.py<br>  │   ├── middlewares.py<br>  │   ├── pipelines.py<br>  │   ├── settings.py<br>  │   └── spiders<br>  │       ├── <strong>init</strong>.py<br>  │       ├── <strong>pycache</strong><br>  │       │   ├── <strong>init</strong>.cpython-37.pyc<br>  │       │   ├── config.cpython-37.pyc<br>  │       │   └── ins.cpython-37.pyc<br>  │       ├── config.py<br>  │       └── ins.py<br>  └── scrapy.cfg</p>
<p>  6 directories, 21 files</p>
</blockquote>
<p>打开 <strong>ins_crawl/spider/ins.py</strong> 文件，代码如下，注意看注释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> (urlencode, urljoin)</span><br><span class="line"><span class="keyword">from</span> ins_crawl.spiders.config <span class="keyword">import</span> * <span class="comment"># 我在同目录下新建了一个config.py</span></span><br><span class="line"><span class="keyword">from</span> ins_crawl.items <span class="keyword">import</span> InsCrawlItem</span><br><span class="line"></span><br><span class="line">LOGGER = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InsSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;ins&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;instagram.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://instagram.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, username=<span class="string">&#x27;taeri__taeri&#x27;</span>, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :params username:用户名，可以在命令行传参</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(InsSpider, self).__init__(*args, **kwargs)</span><br><span class="line">        self.username = username</span><br><span class="line">        self.shared_data = self.get_shared_data() <span class="comment"># 获取shared_data</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request</span>(<span class="params">self, end_cursor, callback</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        request 方法，作用如其名</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        url = urljoin(self.start_urls[<span class="number">0</span>], <span class="string">&#x27;graphql/query/&#x27;</span>) + <span class="string">&#x27;?&#x27;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;query_hash&#x27;</span>: <span class="string">&#x27;f2405b236d85e8296cf30347c9f08c2a&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;variables&#x27;</span>:</span><br><span class="line">                <span class="string">&#x27;&#123;&#123;&quot;id&quot;:&quot;&#123;0&#125;&quot;,&quot;first&quot;:&#123;1&#125;,&quot;after&quot;:&quot;&#123;2&#125;&quot;&#125;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    self.user_id, <span class="number">50</span>, end_cursor),</span><br><span class="line">        &#125;</span><br><span class="line">        url = url + urlencode(params)</span><br><span class="line">        request = scrapy.Request(url=url, callback=callback, meta=&#123;<span class="string">&#x27;proxy&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:8001&#x27;</span>&#125;) <span class="comment"># 这里需要使用proxy，所以添加参数meta</span></span><br><span class="line">        <span class="comment"># 添加 cookies</span></span><br><span class="line">        request.cookies[<span class="string">&#x27;csrftoken&#x27;</span>] = CSRFTOKEN</span><br><span class="line">        <span class="comment"># 添加 headers （其实这个可以删了，我忘了，我在settings里已经设置好了</span></span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> request</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重写start_requests方法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 首先获取 user id 和 count</span></span><br><span class="line">        <span class="keyword">if</span> self.shared_data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            user = self.shared_data[<span class="string">&#x27;entry_data&#x27;</span>][<span class="string">&#x27;ProfilePage&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;graphql&#x27;</span>][<span class="string">&#x27;user&#x27;</span>]</span><br><span class="line">            self.user_id = user[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">            self.count = user[<span class="string">&#x27;edge_owner_to_timeline_media&#x27;</span>][<span class="string">&#x27;count&#x27;</span>]</span><br><span class="line">            LOGGER.info(<span class="string">&#x27;\n&#123;&#125;\nUser id:&#123;&#125;\nTotal &#123;&#125; photos.\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;-&#x27;</span>*<span class="number">20</span>, self.user_id, self.count, <span class="string">&#x27;-&#x27;</span>*<span class="number">20</span>))</span><br><span class="line">            <span class="keyword">for</span> i, url <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.start_urls):</span><br><span class="line">                <span class="keyword">yield</span> self.request(<span class="string">&quot;&quot;</span>, self.parse_item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            LOGGER.error(<span class="string">&#x27;-----[ERROR] shared_data is None.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        j = json.loads(response.text)</span><br><span class="line">        edge_media = j[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;user&#x27;</span>][<span class="string">&#x27;edge_owner_to_timeline_media&#x27;</span>]</span><br><span class="line">        edges = edge_media[<span class="string">&#x27;edges&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> edges:</span><br><span class="line">            <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">                item = InsCrawlItem()</span><br><span class="line">                item[<span class="string">&#x27;image_url&#x27;</span>] = edge[<span class="string">&#x27;node&#x27;</span>][<span class="string">&#x27;display_url&#x27;</span>]</span><br><span class="line">                item[<span class="string">&#x27;username&#x27;</span>] = self.username</span><br><span class="line">                <span class="keyword">yield</span> item</span><br><span class="line">            has_next_page = edge_media[<span class="string">&#x27;page_info&#x27;</span>][<span class="string">&#x27;has_next_page&#x27;</span>]</span><br><span class="line">            <span class="keyword">if</span> has_next_page:</span><br><span class="line">                end_cursor = edge_media[<span class="string">&#x27;page_info&#x27;</span>][<span class="string">&#x27;end_cursor&#x27;</span>]</span><br><span class="line">                <span class="keyword">yield</span> self.request(end_cursor, self.parse_item)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                LOGGER.info(<span class="string">&#x27;获取照片完毕.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_shared_data</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        获取 shared data</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            proxies = &#123;</span><br><span class="line">                <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://&#x27;</span> + PROXY,</span><br><span class="line">                <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://&#x27;</span> + PROXY</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">with</span> requests.get(self.start_urls[<span class="number">0</span>] + self.username, proxies=proxies) <span class="keyword">as</span> resp:</span><br><span class="line">            <span class="comment"># with scrapy.Request(self.start_urls[0] + self.username, meta=&#123;&#x27;proxy&#x27;:&#x27;http://&#x27; + PROXY&#125;) as resp:</span></span><br><span class="line">                html = resp.text</span><br><span class="line">                <span class="keyword">if</span> html <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="string">&#x27;_sharedData&#x27;</span> <span class="keyword">in</span> html:</span><br><span class="line">                    shared_data = html.split(<span class="string">&quot;window._sharedData = &quot;</span>)[<span class="number">1</span>].split(</span><br><span class="line">                        <span class="string">&quot;;&lt;/script&gt;&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> shared_data:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&#x27;Not found [share data]&#x27;</span>)</span><br><span class="line">                        exit(<span class="number">1</span>)</span><br><span class="line">                    <span class="keyword">return</span> json.loads(shared_data)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> exc:</span><br><span class="line">            LOGGER.error(<span class="string">&#x27;[-----]&#x27;</span>, <span class="built_in">repr</span>(exc))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>config.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PROXY = <span class="string">&#x27;127.0.0.1:8001&#x27;</span> <span class="comment"># 代理</span></span><br><span class="line">CSRFTOKEN = <span class="string">&#x27;&#x27;</span> <span class="comment"># cookie中的csrftoken</span></span><br></pre></td></tr></table></figure>

<p>items.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InsCrawlItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    image_url = scrapy.Field() <span class="comment"># 照片链接</span></span><br><span class="line">    username = scrapy.Field() <span class="comment"># 用户名（用不到了</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Pipelines 里没动，就不贴了</p>
<p>InsImagesPipeline.py，有官方提供的例子改的，<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/media-pipeline.html">media-pipeline</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line">LOGGER = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InsImagesPipeline</span>(<span class="params">ImagesPipeline</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span>(<span class="params">self, item, info</span>):</span> <span class="comment"># 请求</span></span><br><span class="line">        image_url = item[<span class="string">&#x27;image_url&#x27;</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(image_url, meta=&#123;<span class="string">&#x27;proxy&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:8001&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span>(<span class="params">self, results, item, info</span>):</span> <span class="comment"># 请求结果</span></span><br><span class="line">        image_paths = [x[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">&quot;Item contains no images&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-----[DOWLOADING]开始下载:&#x27;</span>, item[<span class="string">&#x27;image_url&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>InsProxyMiddlewares.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ins_crawl.spiders.config <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InsProxyMiddlewares</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http://127.0.0.1:8001&#x27;</span></span><br></pre></td></tr></table></figure>

<p>settings.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">&#x27;scrapy&#x27;</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">&#x27;ins_crawl.spiders&#x27;</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">&#x27;ins_crawl.spiders&#x27;</span></span><br><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;ins_crawl.middlewares.InsCrawlDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;ins_crawl.pipelines.InsCrawlPipeline&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">   <span class="string">&#x27;ins_crawl.images.InsImagesPipeline.InsImagesPipeline&#x27;</span>:<span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片保存目录</span></span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;/Users/2h0n91i2hen/Pictures/Instagram/&#x27;</span></span><br></pre></td></tr></table></figure>



<h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><p>taeri__taeri 该用户目前有 430张照片</p>
<p>抓取430张照片</p>
<p>Scrapy 耗时87秒， 0.20232558139534884 / 张。</p>
<p><img src="images/1.jpg" alt="scrapy"></p>
<p>asyncio+aiohttp 耗时21秒， 0.04883720930232558 / 张</p>
<p><img src="images/2.jpg" alt="asyncio"></p>
<hr>
<p>之后我换了个用户：ponysmakeup，照片数量是964</p>
<p>asyncio+aiohttp 耗时42.9秒，0.04450207468879668 / 张</p>
<p><img src="images/3.jpg" alt="asyncio"></p>
<p>而scrapy 耗时159.9秒， 0.1658713692946058 / 张</p>
<p><img src="images/4.jpg" alt="scrapy"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我一开始以为scrapy会很快，没想到比不过asyncio+aiohttp这阵容，我打算用 aiohttp+asyncio+aioredis 写一个代理池，预算用一个礼拜吧，不知道要多久 (:</p>
<p>项目：<a target="_blank" rel="noopener" href="https://github.com/ZCKun/Crawler/tree/master/instagram_crawler/scrapy/ins_crawl">ins_crawl</a></p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%96%87"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C"><span class="toc-number">2.0.1.</span> <span class="toc-text">运行</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&text=Python Scrapy - Ins爬虫"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&is_video=false&description=Python Scrapy - Ins爬虫"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python Scrapy - Ins爬虫&body=Check out this article: http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&title=Python Scrapy - Ins爬虫"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://zckun.github.io/2019/05/17/python-scrapy-crawl-ins-19-05-17/&name=Python Scrapy - Ins爬虫&description=&lt;h2 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;  上午写完那篇文章后，下午在睡觉，晚上就想试试scrapy比较一下速度，那个更快，我是第一次用scrapy下载图片，第一次我使用requests下载的。。。贼鸡儿慢，就是单线程；后来翻了翻文档按照官方的例子改了改算是成功了，这篇文章就说一下我遇到的坑吧，文末对比两者速度&lt;/p&gt;
&lt;/blockquote&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2021 0x2h
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?b1bcce32f51ad876ecf02282881e609b";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


</body>
</html>
