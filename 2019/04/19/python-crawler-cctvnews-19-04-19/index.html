<!DOCTYPE html>
<html lang=zh>
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="前言以 央视网新闻 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识">
<meta name="keywords" content="python,爬虫,html">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）">
<meta property="og:url" content="http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/index.html">
<meta property="og:site_name" content="0x2h">
<meta property="og:description" content="前言以 央视网新闻 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-678097edf4e83d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-31a5b5800ed58aa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-42a2ad4a24c1eb41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-b179eff2db87f1df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-6f27999c272cdab4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-32665626105592fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-9c3f1b875d479e3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-61755e90cccfb5fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-cd1cecd85b52d32f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-124e4c9d165234f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-056d7c68d8fb306a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-aae57a7dca6c34d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-d3dac75a569fd62b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-75fe65ab8e9f8f28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/3702047-6fae8afc8ecfa97d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2019-04-19T12:18:53.446Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）">
<meta name="twitter:description" content="前言以 央视网新闻 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/3702047-678097edf4e83d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </span>
    <br>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2019/04/21/python-anti-crawler-of-font-19-04-21/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2019/04/16/python-crawler-tiktok-19-04-16/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&text=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&is_video=false&description=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）&body=Check out this article: http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&name=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）&description=&lt;h1 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;以 &lt;strong&gt;央视网新闻&lt;/strong&gt; 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识&lt;br&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">2.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <span itemprop="name">0x2h</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2019-04-19T12:04:39.000Z" itemprop="datePublished">2019-04-19</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/html/">html</a>, <a class="tag-link" href="/tags/python/">python</a>, <a class="tag-link" href="/tags/爬虫/">爬虫</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>以 <strong>央视网新闻</strong> 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识<br><a id="more"></a></p>
<blockquote>
<p>至于爬虫、HTML是什么我就不废话了，你如果就连这都不知道就不会看了<br>我这里用的是 Python 来爬，原因就是第三方库多、好用，不用那么费劲找/造 轮子</p>
<p>配置详情:</p>
<ul>
<li>python 3.7</li>
<li>requests （网络请求）</li>
<li>BeautifulSoup （解析）</li>
</ul>
</blockquote>
<p> 首先打开 <a href="http://news.cctv.com/" target="_blank" rel="noopener">央视网新闻</a> 进入首页，我们需要获取的是 <strong>要闻</strong> <img src="https://upload-images.jianshu.io/upload_images/3702047-678097edf4e83d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="要闻"></p>
<p> 不过我在最下面看到了 <strong>点击查看更多内容</strong> 的一个链接，这个先不管，只要先知道有就行了；既然要获取要闻的内容，那我们就得获取要闻的源网页内容了，按下键盘上的 F12 打开开发者工具，或者将鼠标放在网页上右键然后点击开发者工具也是一样的，如果你是 Android 手机上的 Chrome 或者 Firefox，你只需要在你这个网页链接前面加上 <strong>view-source</strong> 就行了，因为手机上的浏览器没有开发者工具，所以就直接查看源代码（PC上的浏览器也可以在链接前面加 view-source 查看源代码）</p>
<p> 刚打开肯定是这样的<br><img src="https://upload-images.jianshu.io/upload_images/3702047-31a5b5800ed58aa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="开发者工具"><br> 点一下左上角的那个有着类似 鼠标 图标按钮<br><img src="https://upload-images.jianshu.io/upload_images/3702047-42a2ad4a24c1eb41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br> 接着把鼠标移动到网页里，这时候Element项里会锁定到你鼠标经过的每一个element，element单词意思为元素，也就是 “h1 title html body div” 叫做标签的这些东西<br><img src="https://upload-images.jianshu.io/upload_images/3702047-b179eff2db87f1df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="element select"><br> 随便点一条要闻，看看在html里是什么，比如这样<br><img src="https://upload-images.jianshu.io/upload_images/3702047-6f27999c272cdab4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 我点的是这篇要闻的标题，可以看到在 Element 里出现在 a 标签里，a标签是html里的超链接，不懂看这<a href="https://developer.mozilla.org/zh-CN/docs/Learn/HTML/Introduction_to_HTML/Creating_hyperlinks#%E4%BB%80%E4%B9%88%E6%98%AF%E8%B6%85%E9%93%BE%E6%8E%A5" target="_blank" rel="noopener">什么是超链接</a></p>
<p> 每个网站如果它显示了很多条内容，比如这个新闻网站里，它要显示很多条新闻，所以它每一条新闻。。。。你可以把这个每一条新闻想象成一块东西，新闻网里有很多很多块，其实内部都一样（我他妈在说什么…</p>
<p> 看向这里<br><img src="https://upload-images.jianshu.io/upload_images/3702047-32665626105592fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 是不是觉得和我上面说的很多很多块一样，有多少新闻内容就有多少这样的div标签，它们的class都是一样的，目的就是为了能很方面的控制这些内容，我们只需要把这些div都扒下来然后慢慢解析出每条新闻的 <strong>标题、内容、详细链接</strong> 就行了，好吧，打开你的编辑器，开始写代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests <span class="comment"># 网络请求用到的</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">​</span><br><span class="line">url = <span class="string">"http://news.cctv.com/"</span></span><br><span class="line"><span class="comment"># headers 是最基本的反爬虫手段，一般来说只需要加User-Agent就行了，User-Agent是浏览器标识，判断你是不是浏览器的方法</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36"</span>, <span class="comment"># 养成好习惯，在字典里每写完一项就在其后面加逗号，哪怕这是最后一项</span></span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 使用 requests 中的 get 方法来达到网络请求</span></span><br><span class="line"><span class="comment"># 其中第一个参数永远都是url，后面的参数需要指定参数名</span></span><br><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment"># 判断返回的状态是不是200，200代表请求OK，这些状态码可以在网上自行了解</span></span><br><span class="line"><span class="keyword">if</span> resp.status_code != <span class="number">200</span>:</span><br><span class="line">    print(<span class="string">"请求失败!"</span>)</span><br><span class="line">    sys.exit() <span class="comment"># 没有请求成功就直接退出</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 接着开始解析</span></span><br><span class="line">soup = BeautifulSoup(resp.text, <span class="string">'html.parser'</span>) <span class="comment"># BeautifulSoup 需要为其指定一个解析器，没有特殊需求html.parser就行了</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">soup.find_all 这个方法很容易理解，如果我只传入我想要获取的标签</span></span><br><span class="line"><span class="string">比如soup.find_all('div')，那么它会返回整个HTML里的所有div的集合给你</span></span><br><span class="line"><span class="string">当然它还有一个参数为了方便我们准确定位到某个标签，那就是attrs，比如我要获取class为continer的div</span></span><br><span class="line"><span class="string">soup.find_all('div', attrs=&#123;'class': 'continer'&#125;) 就行了</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 我为了避免获取到一些不是要闻里的内容就先获取要闻的曾祖父</span></span><br><span class="line">col_w660 = soup.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'col_w660'</span>&#125;)</span><br><span class="line"><span class="comment"># 接着用它曾祖父获取它爷爷</span></span><br><span class="line">main = col_w660.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'main'</span>&#125;)</span><br><span class="line"><span class="comment"># 接着用它爷爷获取它爹</span></span><br><span class="line">mbd = main.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'mhd'</span>&#125;)</span><br><span class="line"><span class="comment"># 接着从它爹那获取它爹的一堆儿子</span></span><br><span class="line">con02s = mbd.find_all(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'ecoA9805_con02'</span>&#125;)</span><br><span class="line"><span class="comment"># 接着输出康一康</span></span><br><span class="line"><span class="keyword">for</span> con02 <span class="keyword">in</span> con02s:</span><br><span class="line">    print(con02)</span><br><span class="line">print(<span class="string">'done'</span>) <span class="comment"># 运行完了提示一下自己</span></span><br></pre></td></tr></table></figure></p>
<p> 接着运行，我是在终端里运行的，命令如下<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  python3 test.py</span><br></pre></td></tr></table></figure></p>
<p> 一回车，WTF，真是一顿操作猛如虎，xxxxxx<br><img src="https://upload-images.jianshu.io/upload_images/3702047-9c3f1b875d479e3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br> 看看是哪里出了问题，既然什么都没有输出，那么就说明 con02s 是没有内容的，我们看看 “它爹” 里是什么<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mbd = main.find(<span class="string">'div'</span>, attrs=&#123;<span class="string">'class'</span>: <span class="string">'mhd'</span>&#125;)</span><br><span class="line">print(mbd) <span class="comment"># 打印它爹</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜ python3 test.py</span><br><span class="line">&lt;div class="mhd"&gt;&lt;span class="mh_title"&gt;è¦•é•»&lt;/span&gt;&lt;span class="moption"&gt;&lt;a href="javascript:getNewData()"&gt;æ•´æ•°0æ•¡æ•°é•»ï¼•ç•¹å•»å•·æ•°&lt;/a&gt; &lt;a class="shuaxin" href="javascript:getNewData()"&gt;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">done</span><br><span class="line">➜</span><br></pre></td></tr></table></figure>
<p> 我他x，这输出的是什么鬼东西，还有乱码；诶，注意，这里的乱码是因为我们获取的网页编码和我们获取到的网页编码不一样导致的，比如源网页为gbk编码的字节流，而我们抓取下后程序直接使用utf-8进行编码并输出到存储文件中，这必然会引起乱码；这里我发现我们抓取的网页的编码为 utf-8，解决办法很简单，需要修改的地方如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> resp.status_code != <span class="number">200</span>:</span><br><span class="line"> print(<span class="string">"请求失败!"</span>)</span><br><span class="line"> sys.exit()</span><br><span class="line">resp.encoding = <span class="string">'utf-8'</span> <span class="comment"># 添加这一行即可</span></span><br><span class="line">​</span><br><span class="line">soup = BeautifulSoup(resp.text, <span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure></p>
<p> 再运行看看<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  python3 test.py</span><br><span class="line">&lt;div class="mhd"&gt;&lt;span class="mh_title"&gt;要闻&lt;/span&gt;&lt;span class="moption"&gt;&lt;a href="javascript:getNewData()"&gt;更新0条新闻，点击刷新&lt;/a&gt; &lt;a class="shuaxin" href="javascript:getNewData()"&gt;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">done</span><br><span class="line">➜</span><br></pre></td></tr></table></figure></p>
<p> 可以看到没有新闻，这是为毛呢，不知道大家知不知道 ajax，全称 Asynchronous Javascript And XML，JavaScript 里的异步请求方法，很多网站在加载数据的时候为了保证网页不刷新的情况下会用到 ajax 技术，用起来也很简单，这里就不装逼了；怎么获取 ajax 请求呢，打开 开发者工具（F12）后，找到 Network 选项，然后刷新网页，你会发现出现了很多条目，那就是页面加载过程中浏览器与服务器之前发送的请求和接受的响应的所有记录<br><img src="https://upload-images.jianshu.io/upload_images/3702047-61755e90cccfb5fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="响应"></p>
<p> ajax 有个很特殊的请求类型，就是 xhr，你可以在 Network 窗口下看到 XHR 过滤按钮，默认是 all，切换到 XHR 就能看到所有的 ajax 请求了，这里有一个请求</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3702047-cd1cecd85b52d32f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 选择那条后可以看到详细请求信息</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3702047-124e4c9d165234f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> Headers 是请求头，Preview 是预览返回的内容，Response 是响应的内容，Cookies 是浏览器缓存，Timing 是请求的耗时啥的（我瞎说的；我们只需要看看Response就行了<br><img src="https://upload-images.jianshu.io/upload_images/3702047-056d7c68d8fb306a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 很明显这是json，如果你觉得这看不懂，或者看着很恶心，那就点 Preview 吧</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3702047-aae57a7dca6c34d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 这样舒服了吧，点开 rollData 项，可以看到里面的内容和网页中的一样</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3702047-d3dac75a569fd62b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 哎，这就很虚浮，回到Headers，看看是怎么请求的，我们要获取这玩意儿</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3702047-75fe65ab8e9f8f28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p> 首先看到General，Request Url为请求的url，Request Method为请求方法，Status Code为状态码，Remote Address为远程服务端的主机地址和端口，Referrer Policy为Referer判断策略；<br> 接着看向 Request Headers，这是我们需要的东西，但也不是全部都要，修改之前的代码，算了直接新建一个文件吧<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">​</span><br><span class="line">url = <span class="string">"http://news.cctv.com/data/index.json"</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'ozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line"><span class="keyword">if</span> resp.status_code != <span class="number">200</span>:</span><br><span class="line">    print(<span class="string">'请求失败!'</span>)</span><br><span class="line">    sys.exit()</span><br><span class="line"><span class="comment"># 因为我事先知道返回的结果是json格式的，所以直接调用json()方法即可，返回的是字典对象</span></span><br><span class="line">print(resp.json())</span><br></pre></td></tr></table></figure></p>
<p> 运行<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  python3 test.py</span><br><span class="line">&#123;'rollData': [&#123;'title': '中共中央政治局召开会议 中共中央总书记习近平主持会议'...</span><br><span class="line">➜</span><br></pre></td></tr></table></figure></p>
<p> 成功的获取到了我们需要的东西，很长很长一堆，我省略了，接着就开始解析吧，解析的结果我就把它保存到MongoDB，关于MongoDB的安装以及配置你可以百度或者以后我写一篇文章<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在上面的代码下追加</span></span><br><span class="line"><span class="keyword">import</span> pymongo <span class="comment"># python 操作 mongodb 的库</span></span><br><span class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>) <span class="comment"># 与本地mongodb建立连接</span></span><br><span class="line">db = client[<span class="string">'cctv_news'</span>] <span class="comment"># </span></span><br><span class="line">​</span><br><span class="line">rollData = resp.json()[<span class="string">'rollData'</span>]</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rollData:</span><br><span class="line">    collection = &#123;</span><br><span class="line">        <span class="string">'标题'</span>: data[<span class="string">'title'</span>],</span><br><span class="line">        <span class="string">'Desc'</span>: data[<span class="string">'description'</span>],<span class="comment"># 原谅我见识少实在不知道怎么解释这里的description</span></span><br><span class="line">        <span class="string">'发布时间'</span>: data[<span class="string">'dataTime'</span>],</span><br><span class="line">        <span class="string">'原文链接'</span>: data[<span class="string">'url'</span>],</span><br><span class="line">        <span class="string">'标签'</span>: data[<span class="string">'content'</span>],</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> db[<span class="string">'news'</span>].insert_one(collection):</span><br><span class="line">            print(<span class="string">'存储到MongoDB成功.'</span>, collection)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'存储到MongoDB失败！'</span>)</span><br></pre></td></tr></table></figure></p>
<p> 然后运行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  python3 test.py</span><br><span class="line">存储到MongoDB成功. &#123;<span class="string">'标题'</span>: <span class="string">'内蒙古一男子非法雇佣“三非”外国人被查获'</span>...</span><br></pre></td></tr></table></figure></p>
<p> 看看MongoDB里，成功保存<br><img src="https://upload-images.jianshu.io/upload_images/3702047-6fae8afc8ecfa97d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p> 其实爬虫的用途非常非常的多，爬虫就是为了搜集网络上的数据存在的，我还学识尚浅；这篇文章可能是我写过最长的了，也是可笑，我觉得我写得应该还算详细，有些知识点如果不懂可以留言问我</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">2.</span> <span class="toc-text">总结</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&text=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&is_video=false&description=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）&body=Check out this article: http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&title=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://zckun.github.io/2019/04/19/python-crawler-cctvnews-19-04-19/&name=Python爬虫 - 抓取央视网新闻要闻-新手向（第一篇）&description=&lt;h1 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;以 &lt;strong&gt;央视网新闻&lt;/strong&gt; 网站为例，详细讲一下怎么写爬虫，会涉及到一些HTML知识&lt;br&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 0x2h
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


</body>
</html>
